{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sklearn # or pip \n",
    "#!pip3 install numpy\n",
    "#!pip3 install torch torchvision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sameple x [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]]\n",
      "Sample y [0 0 0]\n",
      "Labels iris  ['setosa' 'versicolor' 'virginica']\n",
      "Feature names ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Sameple x scaled\n",
      " [[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "from   matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from   torch.autograd import Variable\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "print(\"Sameple x\", X[:3])\n",
    "print(\"Sample y\", y[:3])\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "print(\"Labels iris \", names)\n",
    "print(\"Feature names\", feature_names)\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "# removes mean and divides by standard deviation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Sameple x scaled\\n\", X_scaled[:3])\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, shuffle = True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (120, 4) (30, 4)\n",
      "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled.shape, X_train.shape, X_val.shape)\n",
    "print(X_scaled[:3])\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 4]) torch.Size([120])\n",
      "torch.float32 torch.int64\n",
      "torch.Size([30, 4]) torch.Size([30])\n",
      "torch.float32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "# convert data from numpy to tensors\n",
    "X_t_train = t.from_numpy(X_train).float()\n",
    "y_t_train = t.flatten(t.from_numpy(y_train).long()) # flatten - creates a one dimensional tensor\n",
    "X_t_val   = t.from_numpy(X_val).float()\n",
    "y_t_val   = t.flatten(t.from_numpy(y_val).long())\n",
    "\n",
    "print(X_t_train.shape, y_t_train.shape)\n",
    "print(X_t_train.dtype, y_t_train.dtype)\n",
    "print(X_t_val.shape,   y_t_val.shape)\n",
    "print(X_t_val.dtype,   y_t_val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train_data =  [(tensor([ 0.4322, -0.5924,  0.5922,  0.7907]), tensor(2)), (tensor([-0.9007,  0.5586, -1.1697, -0.9205]), tensor(0)), (tensor([-0.2948, -0.3622, -0.0898,  0.1325]), tensor(1))]  type =  <class 'list'>\n",
      "tensor([[-1.7489, -0.1320, -1.3971, -1.3154],\n",
      "        [ 0.7957, -0.1320,  0.8196,  1.0539],\n",
      "        [-0.1737,  3.0908, -1.2834, -1.0522],\n",
      "        [-0.9007,  1.0190, -1.3402, -1.1838],\n",
      "        [-1.0218,  1.2492, -1.3402, -1.3154],\n",
      "        [-0.7795,  1.0190, -1.2834, -1.3154],\n",
      "        [ 0.4322, -0.5924,  0.5922,  0.7907],\n",
      "        [ 1.0380,  0.5586,  1.1038,  1.1856],\n",
      "        [-1.1430, -0.1320, -1.3402, -1.3154],\n",
      "        [ 1.4015,  0.3284,  0.5354,  0.2641]]) tensor([0, 2, 0, 0, 0, 0, 2, 2, 0, 1])\n",
      "tensor([[ 0.3110, -0.1320,  0.4786,  0.2641],\n",
      "        [-1.8700, -0.1320, -1.5107, -1.4471],\n",
      "        [-1.1430,  1.2492, -1.3402, -1.4471],\n",
      "        [ 1.0380,  0.0982,  1.0469,  1.5805],\n",
      "        [ 1.1592, -0.1320,  0.9901,  1.1856],\n",
      "        [ 1.2803,  0.0982,  0.6491,  0.3958],\n",
      "        [ 0.1898, -0.3622,  0.4217,  0.3958],\n",
      "        [ 0.9168, -0.1320,  0.3649,  0.2641],\n",
      "        [-0.9007,  1.0190, -1.3402, -1.3154],\n",
      "        [-0.2948, -0.3622, -0.0898,  0.1325]]) tensor([1, 0, 0, 2, 2, 1, 1, 1, 0, 1])\n",
      "tensor([[-1.1430e+00, -1.2830e+00,  4.2173e-01,  6.5904e-01],\n",
      "        [-5.3718e-01,  7.8881e-01, -1.2834e+00, -1.0522e+00],\n",
      "        [-4.1601e-01, -1.0528e+00,  3.6490e-01,  8.7755e-04],\n",
      "        [ 1.7650e+00, -3.6218e-01,  1.4448e+00,  7.9067e-01],\n",
      "        [ 1.8983e-01, -1.3198e-01,  5.9225e-01,  7.9067e-01],\n",
      "        [ 5.5333e-01, -1.2830e+00,  7.0592e-01,  9.2230e-01],\n",
      "        [ 5.5333e-01, -8.2257e-01,  6.4908e-01,  7.9067e-01],\n",
      "        [-5.2506e-02, -8.2257e-01,  8.0709e-02,  8.7755e-04],\n",
      "        [-1.7489e+00, -3.6218e-01, -1.3402e+00, -1.3154e+00],\n",
      "        [-9.0068e-01,  5.5861e-01, -1.1697e+00, -9.2055e-01]]) tensor([2, 0, 1, 2, 2, 2, 2, 1, 0, 0])\n",
      "tensor([[ 1.8862e+00, -5.9237e-01,  1.3311e+00,  9.2230e-01],\n",
      "        [ 4.3217e-01, -3.6218e-01,  3.0806e-01,  1.3251e-01],\n",
      "        [ 1.5227e+00, -1.3198e-01,  1.2175e+00,  1.1856e+00],\n",
      "        [-1.7367e-01, -5.9237e-01,  1.9438e-01,  1.3251e-01],\n",
      "        [ 3.1100e-01, -1.0528e+00,  1.0469e+00,  2.6414e-01],\n",
      "        [ 1.8983e-01, -1.9736e+00,  7.0592e-01,  3.9577e-01],\n",
      "        [ 2.1285e+00, -1.3198e-01,  1.6153e+00,  1.1856e+00],\n",
      "        [-5.2506e-02, -1.0528e+00,  1.3755e-01,  8.7755e-04],\n",
      "        [-1.7367e-01,  1.7096e+00, -1.1697e+00, -1.1838e+00],\n",
      "        [-1.1430e+00,  9.8217e-02, -1.2834e+00, -1.3154e+00]]) tensor([2, 1, 2, 1, 2, 2, 2, 1, 0, 0])\n",
      "tensor([[-0.7795,  0.7888, -1.3402, -1.3154],\n",
      "        [-0.0525, -0.8226,  0.7628,  0.9223],\n",
      "        [-0.2948, -0.1320,  0.1944,  0.1325],\n",
      "        [ 1.1592,  0.3284,  1.2175,  1.4488],\n",
      "        [ 0.3110, -0.5924,  0.1375,  0.1325],\n",
      "        [-0.5372,  0.7888, -1.1697, -1.3154],\n",
      "        [ 0.9168, -0.3622,  0.4786,  0.1325],\n",
      "        [-1.2642,  0.0982, -1.2266, -1.3154],\n",
      "        [ 1.2803,  0.0982,  0.9333,  1.1856],\n",
      "        [-0.0525,  2.1700, -1.4539, -1.3154]]) tensor([0, 2, 1, 2, 1, 0, 1, 0, 2, 0])\n",
      "tensor([[-2.9484e-01, -1.2830e+00,  8.0709e-02, -1.3075e-01],\n",
      "        [-4.1601e-01, -1.7434e+00,  1.3755e-01,  1.3251e-01],\n",
      "        [ 6.7450e-01,  9.8217e-02,  9.9011e-01,  7.9067e-01],\n",
      "        [ 1.8983e-01, -1.9736e+00,  1.3755e-01, -2.6239e-01],\n",
      "        [-5.2506e-02, -5.9237e-01,  7.6276e-01,  1.5805e+00],\n",
      "        [ 6.8662e-02, -1.3198e-01,  7.6276e-01,  7.9067e-01],\n",
      "        [-7.7951e-01,  2.4002e+00, -1.2834e+00, -1.4471e+00],\n",
      "        [-1.1430e+00, -1.5132e+00, -2.6032e-01, -2.6239e-01],\n",
      "        [ 3.1100e-01, -5.9237e-01,  5.3541e-01,  8.7755e-04],\n",
      "        [-1.7367e-01, -5.9237e-01,  4.2173e-01,  1.3251e-01]]) tensor([1, 1, 2, 1, 2, 2, 0, 1, 1, 1])\n",
      "tensor([[ 0.7957, -0.1320,  1.1606,  1.3172],\n",
      "        [ 0.5533,  0.7888,  1.0469,  1.5805],\n",
      "        [ 0.0687,  0.3284,  0.5922,  0.7907],\n",
      "        [ 1.1592, -0.5924,  0.5922,  0.2641],\n",
      "        [ 0.5533, -1.2830,  0.6491,  0.3958],\n",
      "        [-0.7795, -0.8226,  0.0807,  0.2641],\n",
      "        [-0.4160,  1.0190, -1.3971, -1.3154],\n",
      "        [-0.4160, -1.5132, -0.0330, -0.2624],\n",
      "        [ 0.0687, -0.1320,  0.2512,  0.3958],\n",
      "        [-0.9007,  1.7096, -1.2266, -1.3154]]) tensor([2, 2, 1, 1, 1, 1, 0, 1, 1, 0])\n",
      "tensor([[-0.5372,  1.9398, -1.3971, -1.0522],\n",
      "        [ 1.2803,  0.0982,  0.7628,  1.4488],\n",
      "        [-0.5372, -0.1320,  0.4217,  0.3958],\n",
      "        [-0.9007,  0.7888, -1.2834, -1.3154],\n",
      "        [-1.5065,  0.3284, -1.3402, -1.3154],\n",
      "        [-1.0218, -1.7434, -0.2603, -0.2624],\n",
      "        [-1.0218,  0.7888, -1.2266, -1.0522],\n",
      "        [-1.0218, -2.4339, -0.1466, -0.2624],\n",
      "        [ 1.0380,  0.0982,  0.5354,  0.3958],\n",
      "        [ 0.4322, -1.9736,  0.4217,  0.3958]]) tensor([0, 2, 1, 0, 0, 1, 0, 1, 1, 1])\n",
      "tensor([[ 3.1100e-01, -3.6218e-01,  5.3541e-01,  2.6414e-01],\n",
      "        [-1.7367e-01, -1.3198e-01,  2.5122e-01,  8.7755e-04],\n",
      "        [ 5.5333e-01, -5.9237e-01,  7.6276e-01,  3.9577e-01],\n",
      "        [-5.2506e-02, -8.2257e-01,  7.6276e-01,  9.2230e-01],\n",
      "        [-2.9484e-01, -5.9237e-01,  6.4908e-01,  1.0539e+00],\n",
      "        [-5.3718e-01,  1.4794e+00, -1.2834e+00, -1.3154e+00],\n",
      "        [ 5.5333e-01,  5.5861e-01,  5.3541e-01,  5.2741e-01],\n",
      "        [ 5.5333e-01,  5.5861e-01,  1.2743e+00,  1.7121e+00],\n",
      "        [ 4.3217e-01,  7.8881e-01,  9.3327e-01,  1.4488e+00],\n",
      "        [-1.0218e+00,  7.8881e-01, -1.2834e+00, -1.3154e+00]]) tensor([1, 1, 2, 2, 2, 0, 1, 2, 2, 0])\n",
      "tensor([[ 2.2497, -0.5924,  1.6722,  1.0539],\n",
      "        [ 0.7957,  0.3284,  0.7628,  1.0539],\n",
      "        [ 1.6438,  1.2492,  1.3311,  1.7121],\n",
      "        [-0.4160, -1.5132,  0.0239, -0.1308],\n",
      "        [ 2.2497, -1.0528,  1.7858,  1.4488],\n",
      "        [-1.0218,  0.5586, -1.3402, -1.3154],\n",
      "        [ 0.6745, -0.8226,  0.8764,  0.9223],\n",
      "        [-1.0218,  1.0190, -1.3971, -1.1838],\n",
      "        [-0.0525, -0.8226,  0.1944, -0.2624],\n",
      "        [-0.4160,  2.6304, -1.3402, -1.3154]]) tensor([2, 2, 2, 1, 2, 0, 2, 0, 1, 0])\n",
      "tensor([[ 0.1898, -0.8226,  0.7628,  0.5274],\n",
      "        [-0.9007,  1.4794, -1.2834, -1.0522],\n",
      "        [ 1.2803,  0.3284,  1.1038,  1.4488],\n",
      "        [ 0.6745, -0.5924,  1.0469,  1.3172],\n",
      "        [ 2.2497,  1.7096,  1.6722,  1.3172],\n",
      "        [ 2.4920,  1.7096,  1.5016,  1.0539],\n",
      "        [ 0.7957, -0.1320,  0.9901,  0.7907],\n",
      "        [ 1.0380, -0.1320,  0.8196,  1.4488],\n",
      "        [-0.1737, -1.0528, -0.1466, -0.2624],\n",
      "        [-1.1430,  0.0982, -1.2834, -1.4471]]) tensor([1, 0, 2, 2, 2, 2, 2, 2, 1, 0])\n",
      "tensor([[ 1.0380,  0.0982,  0.3649,  0.2641],\n",
      "        [-0.9007,  1.7096, -1.2834, -1.1838],\n",
      "        [ 0.6745,  0.3284,  0.4217,  0.3958],\n",
      "        [-1.5065,  1.2492, -1.5676, -1.3154],\n",
      "        [-1.2642,  0.7888, -1.2266, -1.3154],\n",
      "        [ 0.5533, -0.3622,  1.0469,  0.7907],\n",
      "        [-0.2948, -0.1320,  0.4217,  0.3958],\n",
      "        [ 2.2497, -0.1320,  1.3311,  1.4488],\n",
      "        [-0.9007, -1.2830, -0.4308, -0.1308],\n",
      "        [-1.0218,  1.0190, -1.2266, -0.7889]]) tensor([1, 0, 1, 0, 0, 2, 1, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader = a class that shuffles the data and splits in into batches\n",
    "# you should use it during training (SGD - accumulate error over batches of data )\n",
    "train_data = [(X_t_train[i], y_t_train[i]) for i in range(X_t_train.shape[0])]\n",
    "print(\"Sample train_data = \", train_data[:3], \" type = \", type(train_data))\n",
    "trainloader = t.utils.data.DataLoader(train_data, batch_size = 10, shuffle=True)\n",
    "for x,label in trainloader:  # shuffles the data\n",
    "    print(x,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim = 4):\n",
    "         \n",
    "        super(Model, self).__init__()\n",
    "        self.layer1   = nn.Linear(in_features=input_dim, out_features = 15)\n",
    "        self.dropout1 = nn.Dropout(p = 0.3) # drop 30% of output nodes from the previous layer during training only \n",
    "        self.layer2   = nn.Linear(in_features= 15, out_features = 12)\n",
    "        self.dropout2 = nn.Dropout(p = 0.25)\n",
    "        self.layer3   = nn.Linear(in_features = 12, out_features = 3) # 3 neurons = one for each class\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (layer1): Linear(in_features=4, out_features=15, bias=True)\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (layer2): Linear(in_features=15, out_features=12, bias=True)\n",
      "  (dropout2): Dropout(p=0.25, inplace=False)\n",
      "  (layer3): Linear(in_features=12, out_features=3, bias=True)\n",
      ")\n",
      "tensor([ 0.0011,  0.0695, -0.2049], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model     = Model(X_train.shape[1])   # X_train.shape[1]\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn   = nn.CrossEntropyLoss()\n",
    "print(model)\n",
    "\n",
    "y0 = model.forward(X_t_train[0,:])\n",
    "print(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 1.0436, Validation loss 1.0564\n",
      "Epoch 1, Training loss 1.0315, Validation loss 1.0324\n",
      "Epoch 100, Training loss 0.2047, Validation loss 0.0767\n",
      "Epoch 200, Training loss 0.1565, Validation loss 0.0591\n",
      "Epoch 300, Training loss 0.2439, Validation loss 0.0538\n",
      "Epoch 400, Training loss 0.0073, Validation loss 0.0619\n",
      "Epoch 500, Training loss 0.0164, Validation loss 0.0657\n",
      "Epoch 600, Training loss 0.0838, Validation loss 0.0718\n",
      "Epoch 700, Training loss 0.0437, Validation loss 0.0623\n"
     ]
    }
   ],
   "source": [
    "train_model(n_epochs = 700, model = model, \n",
    "            train_loader = trainloader, optimizer = optimizer, \n",
    "            loss_fn = loss_fn, \n",
    "            x_val   = X_t_val,   y_val = y_t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs, model, train_loader, optimizer, loss_fn, \n",
    "                x_val, y_val):\n",
    "    for epoch in range(n_epochs+1):\n",
    "        for xb,yb in train_loader: # for each batch\n",
    "            model.train()       # set model in training mode = with dropout\n",
    "            ym = model.forward(xb)\n",
    "            loss = loss_fn(ym,yb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 100 == 0:\n",
    "            model.eval() # set model in evaluation mode = no dropout\n",
    "            with t.no_grad():  # no learning\n",
    "                ym_val   = model.forward(x_val)\n",
    "                loss_val = loss_fn(ym_val,y_val)\n",
    "\n",
    "            print(f\"Epoch {epoch}, Training loss {loss.item():.4f},\"\n",
    "f\" Validation loss {loss_val.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  tensor(0.9667)\n",
      "Training accuracy =  tensor(0.9833)\n"
     ]
    }
   ],
   "source": [
    "soft_max  = t.nn.Softmax(1) \n",
    "y_m_train = soft_max(model.forward(X_t_train)) # y_m normalized with softmax\n",
    "y_m_train = t.argmax(y_m_train,dim = 1)\n",
    "\n",
    "y_m_val   = soft_max(model.forward(X_t_val))\n",
    "y_m_val   = t.argmax(y_m_val,dim = 1)\n",
    "correct_pred_val = t.sum(y_m_val == y_t_val)/y_m_val.shape[0]\n",
    "print(\"Validation accuracy = \", correct_pred_val)\n",
    "\n",
    "correct_pred_train = t.sum(y_m_train == y_t_train)/y_m_train.shape[0]\n",
    "print(\"Training accuracy = \", correct_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
