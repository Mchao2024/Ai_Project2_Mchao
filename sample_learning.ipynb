{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/python@3.9/bin/python3.9\n",
      "3.9.4 (default, Apr  5 2021, 01:47:16) \n",
      "[Clang 11.0.0 (clang-1100.0.33.17)]\n",
      "sys.version_info(major=3, minor=9, micro=4, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11]) torch.Size([11])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "from matplotlib import pyplot as plt\n",
    "x_s =  [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "y_s = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "x_t = t.tensor(x_s)\n",
    "y_t = t.tensor(y_s)\n",
    "print(x_t.shape, y_t.shape)\n",
    "plt.plot(x_s,y_s,'*')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0856,  0.3800,  0.4885,  1.8998,  0.0543, -0.2714, -0.8142, -1.5741,\n",
       "        -0.4885,  0.2714,  1.1399])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the data\n",
    "from torch.nn.functional import normalize\n",
    "x_n = (x_t - t.mean(x_t))/t.std(x_t) # normalize(x_t, 2, dim = 0)# (x_t - t.mean(x_t))/t.std(x_t)\n",
    "x_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4972, 2.6973, 2.8339, 4.2419, 2.7210, 2.2814, 1.3902, 0.6713, 2.2517,\n",
       "        2.9646, 3.4399])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_n = (y_t - t.mean(x_t))/t.std(y_t)\n",
    "y_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a linear model y = w * x + b (a line)\n",
    "# find parameters a and b that minimize the error between the points \n",
    "# and the line\n",
    "def model(x, w, b): \n",
    "    return w * x + b\n",
    "\n",
    "# error (mean squared error)\n",
    "# y_predict is a tensor (a vector of values) comes from the model, \n",
    "# y_true = true values - come from the training data \n",
    "def loss_fn(y_predict, y_true):\n",
    "    squared_diffs = (y_predict - y_true)**2  # tensor of  errors\n",
    "    return squared_diffs.mean() # sum of errors/# points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1000) tensor(0.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss =  tensor(6.7603)\n"
     ]
    }
   ],
   "source": [
    "w = 0.1*t.ones(())  # w = 1\n",
    "b = 0.1*t.zeros(()) # b = 0\n",
    "print(w, b)\n",
    "y_p = model(x_n, w, b)\n",
    "plt.plot(x_n, y_p,'ro')\n",
    "plt.plot(x_n, y_n, 'b.')\n",
    "plt.show()\n",
    "\n",
    "# compute the error\n",
    "loss0 = loss_fn(y_p,y_n)\n",
    "print(\"Initial loss = \", loss0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient of loss with respect to w and b\n",
    "# dLoss/dw = d (y_p - y_t)^2)/dw = dLoss/dy_p * dy_p/dw \n",
    "#          = 2 (y_p-y_t) * dy_p/dw = \n",
    "#          = 2 (y_p-y_t) * d(w*x_t + b)/dw = \n",
    "#          = 2 (y_p-y_t) * x_t\n",
    "# dLoss/db = d(y_p - y_t)^2/db= dLoss/dy_p * dy_p/db =\n",
    "#           = 2 (y_p-y_t) * dy_p/db =\n",
    "#           = 2 (y_p-y_t) * d(w*x_t + b)/db = \n",
    "#           = 2 (y_p-y_t) \n",
    "# d x^2 / d x = 2 x \n",
    "def grad_loss (y_p, y_t):\n",
    "    return 2*(y_p-y_t)/y_p.size(0)         # y_p.size(0) = n \n",
    "    \n",
    "def grad_w(x_t, w, b):\n",
    "    return x_t\n",
    "  \n",
    "def grad_b(x_t, w, b):\n",
    "    return 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "def training_loop(n_epochs, learning_rate, w,b  , y_t, x_t, eps = 1e-3):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # forward pass:\n",
    "        y_p  = model(x_t,w,b)   # compute the model's prediction for all x_t points\n",
    "        # backward pass\n",
    "        loss = loss_fn(y_p, y_t) \n",
    "        grad_all = grad_loss(y_p,y_t)  # tensor\n",
    "        w = w - learning_rate * (grad_all * grad_w(x_t, w, b)).sum()\n",
    "        b = b - learning_rate * (grad_all * grad_b(x_t, w, b)).sum()\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss) ) ) \n",
    "        if (loss < 1e-3):\n",
    "            break\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 1.105566\n",
      "Epoch 10, Loss 0.153341\n",
      "Epoch 15, Loss 0.047779\n",
      "Epoch 20, Loss 0.035998\n",
      "Epoch 25, Loss 0.034674\n",
      "Epoch 30, Loss 0.034523\n",
      "Epoch 35, Loss 0.034506\n",
      "Epoch 40, Loss 0.034504\n",
      "Epoch 45, Loss 0.034504\n",
      "Epoch 50, Loss 0.034504\n",
      "Epoch 55, Loss 0.034504\n",
      "Epoch 60, Loss 0.034504\n",
      "Epoch 65, Loss 0.034504\n",
      "Epoch 70, Loss 0.034504\n",
      "Epoch 75, Loss 0.034504\n",
      "Epoch 80, Loss 0.034504\n",
      "Epoch 85, Loss 0.034504\n",
      "Epoch 90, Loss 0.034504\n",
      "Epoch 95, Loss 0.034504\n",
      "Epoch 100, Loss 0.034504\n"
     ]
    }
   ],
   "source": [
    "w = 0.1*t.ones(())  # w = 1\n",
    "b = 0.1*t.ones(()) # b = 0\n",
    "learning_rate = 0.1 # 0.005 # learning rate 0.1, 0.01 # change it to smaller values\n",
    "w_train, b_train = training_loop(100, learning_rate, w, b, y_n, x_n, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9808)\n",
      "tensor(2.4537)\n"
     ]
    }
   ],
   "source": [
    "print(w_train)\n",
    "print(b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_n, model(x_n, w_train, b_train), 'ro')\n",
    "plt.plot(x_n, y_n, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   # neural network module \n",
    "import torch.optim as optim # optimization module (SGD)\n",
    "\n",
    "# nn.Linear(input_size, output_size, bias = True)\n",
    "linear_model = nn.Linear(1, 1) # one neuron similar to y = w*x + b\n",
    "                             # nn.Linear(2,1)  y = w1*x1 + w2*x2 + b\n",
    "                             # nn.Linear(2,2)  y1 = w11*x1 + w12*x2 + b1\n",
    "                             #                 y2 = w21*x1 + w22*x2 + b2\n",
    "print(linear_model.weight, linear_model.bias)\n",
    "print(linear_model.parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.ones(2,1)\n",
    "print(x, x.shape)\n",
    "linear_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  3, 10,  0,  8,  1,  2]) tensor([5, 9, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "# split training - validation\n",
    "n_samples = x_t.shape[0]\n",
    "n_val = int(0.4 * n_samples) # 20 % of the samples for validation\n",
    "shuffled_indices = t.randperm(n_samples)\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "print(train_indices, val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0856],\n",
      "        [ 0.3800],\n",
      "        [ 0.4885],\n",
      "        [ 1.8998],\n",
      "        [ 0.0543],\n",
      "        [-0.2714],\n",
      "        [-0.8142],\n",
      "        [-1.5741],\n",
      "        [-0.4885],\n",
      "        [ 0.2714],\n",
      "        [ 1.1399]])\n",
      "tensor([[1.4972],\n",
      "        [2.6973],\n",
      "        [2.8339],\n",
      "        [4.2419],\n",
      "        [2.7210],\n",
      "        [2.2814],\n",
      "        [1.3902],\n",
      "        [0.6713],\n",
      "        [2.2517],\n",
      "        [2.9646],\n",
      "        [3.4399]])\n"
     ]
    }
   ],
   "source": [
    "x_t_2d = x_n.unsqueeze(1) # adds a dimension\n",
    "y_t_2d = y_n.unsqueeze(1)\n",
    "print(x_t_2d)\n",
    "print(y_t_2d)\n",
    "\n",
    "x_t_train = x_t_2d[train_indices,:]\n",
    "x_t_val   = x_t_2d[val_indices,:]\n",
    "\n",
    "y_t_train = y_t_2d[train_indices,:]\n",
    "y_t_val   = y_t_2d[val_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, x_t_train, x_t_val,\n",
    "                  y_t_train, y_t_val, eps = 0.01):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # forward pass training\n",
    "        y_p_train  = model(x_t_train)\n",
    "        loss_train = loss_fn(y_p_train, y_t_train)\n",
    " \n",
    "        \n",
    "        # backwards training\n",
    "        optimizer.zero_grad()  # sets gradients to 0 \n",
    "        loss_train.backward()  # gradients are computed \n",
    "        optimizer.step()       # parameters ar changed\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            # forward pass validation\n",
    "            y_p_val    = model(x_t_val)\n",
    "            loss_val = loss_fn(y_p_val, y_t_val)\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "f\" Validation loss {loss_val.item():.4f}\")\n",
    "        if loss_train < eps:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Linear(in_features=1, out_features=1, bias=True)>\n",
      "Epoch 1, Training loss 10.3472, Validation loss 5.8628\n",
      "tensor(10.3472, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.0720, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.3100, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9428, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8802, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0528, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4073, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9028, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5077, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1978, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6113, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4918, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3973, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3223, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2628, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2154, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0587, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0253, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(1, 1)  # one input and one output y = w x + b\n",
    "print(linear_model.parameters)\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr= 0.05)  # lr = learning rate\n",
    "training_loop(n_epochs = 100, optimizer = optimizer,  \n",
    "              model    = linear_model,\n",
    "             loss_fn   = nn.MSELoss(), # error function = MSE = Mean Square Error\n",
    "             x_t_train = x_t_train,  x_t_val= x_t_val,\n",
    "             y_t_train = y_t_train, y_t_val = y_t_val, eps = 0.01)\n",
    "# split data into training and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_t, model(x_t, w_train, b_train), 'ro')\n",
    "plt.plot(x_t, y_t, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "df955ce39d0f31d56d4bb2fe0a613e5326ba60723fd33d8303a3aede8f65715c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
